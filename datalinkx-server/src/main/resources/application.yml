server:
  port: 12345

spring:
  application:
    name: datalinkx-server
  datasource:
    driver-class-name: com.mysql.cj.jdbc.Driver
    username: ${MYSQL_USERNAME:root}
    password: ${MYSQL_PASSWORD:123456}
    url: jdbc:mysql://${MYSQL_URL:127.0.0.1}:3306/datalinkx?characterEncoding=UTF-8&autoReconnect=true&serverTimezone=Asia/Shanghai&zeroDateTimeBehavior=convertToNull
  jackson:
    date-format: yyyy-MM-dd HH:mm:ss
    time-zone: GMT+8
    deserialization:
      fail-on-unknown-properties: false
  aop:
    proxy-target-class: true
  jpa:
    hibernate:
      ddl-auto: update
      naming:
        physical-strategy: org.hibernate.boot.model.naming.PhysicalNamingStrategyStandardImpl
  redis:
    database: 0       # Redis数据库索引（默认为0）,如果设置为1，那么存入的key-value都存放在select 1中
    host: ${REDIS_HOST:127.0.0.1}
    port: ${REDIS_PORT:6379}
    password: ${REDIS_PASSWORD:123456}
    timeout: 10000
#  elasticsearch:  # 开启大模型时打开注解
#    rest:
#      uris:

xxl-job:
  username: admin
  password: 123456
  job-group: 3
  exec-handler: dataTransJobHandler
  executor-route-strategy: FIRST
  client:
    url: http://127.0.0.1:8080
    connect_timeout_ms: 20000
    call_timeout_ms: 600000
    read_timeout_ms: 600000
    logging: true

# 流转配置性能
data-transfer:
  # 批次提交行数，读fetch-size行后提交
  fetch-size: 1000
  # 读fetch-size行数据的查询超时时间
  query-time-out: 10000
  # 流式checkpoint地址
  checkpoint-path: file:///tmp

client:
  datajob:
    url: http://localhost:23456
    connect_timeout_ms: 20000
    call_timeout_ms: 600000
    read_timeout_ms: 600000
    logging: true
  flink:
    url: http://localhost:8081
    connect_timeout_ms: 20000
    call_timeout_ms: 600000
    read_timeout_ms: 600000
    logging: true
  ollama:
    url: http://localhost:11434
  deepseek:
    url: https://api.deepseek.com

topic:
  daemon: true

logging:
  pattern:
    console: ${CONSOLE_LOG_PATTERN:%clr(%d{${LOG_DATEFORMAT_PATTERN:yyyy-MM-dd HH:mm:ss.SSS}}){faint} %clr(${LOG_LEVEL_PATTERN:%5p}) %clr(${PID:- }){magenta} [${spring.application.name}] %clr([%10.10t]){faint}[%36.36X{trace_id}] %clr(%-40.40logger{39}){cyan} %clr(:){faint} %m%n${LOG_EXCEPTION_CONVERSION_WORD:%wEx}}
  file:
    name: log/${spring.application.name}.log
  level:
    com.datalinkx: INFO
    org.hibernate.SQL: DEBUG
    org.hibernate.type: DEBUG

retrofit:
  # 日志打印配置
  log:
    # 启用日志打印
    enable: true
    # 日志打印拦截器
    logging-interceptor: com.github.lianjiatech.retrofit.spring.boot.interceptor.DefaultLoggingInterceptor
    # 全局日志打印级别
    global-log-level: info
    # 全局日志打印策略
    global-log-strategy: body

llm:
  #  embedding: "shaw/dmeta-embedding-zh"
  model: "qwen:7b"
  vector: "elasticsearch"
  response_parse: "$.message.content"
  inner_prompt: "不要回答任何多余的说辞和思考过程!只回答我问题的答案，不要长篇大论一句话，越简洁越好"

deepseek:
  #  [deepseek-chat, deepseek-reasoner]
  model: "deepseek-chat"
  api_key: ""
  system_content: |
    角色：你是一名数据分析助手，专注于用简洁的语言解释复杂的数据分析结果。
    如果用户要求你进行可视化分析，请尽量通过生成一个完整的 HTML 页面，使用 ECharts 进行销售数据可视化展示，具体要求如下：
      1. 页面结构包括 `<!DOCTYPE html>`, `<html>`, `<head>`, `<body>`。
      2. 引入 ECharts 库，使用 CDN 链接（例如 https://cdn.jsdelivr.net/npm/echarts）。
      3. 页面中包含一个 `<div id="chart">` 容器，用于渲染图表。
      4. 图表配置（在用户没有特别强调情况下）：
      - 可以根据数据类型（如时间、类别、数值等）设置适当的 X 轴和 Y 轴类型。
      - 根据数据特点（例如条形图、折线图、饼图等）选择合适的图表类型。
      - 提供基本的图表样式和配置，确保图表在不同设备和屏幕尺寸下的良好展示。
      5. 可视化展示内容应清晰、直观，并适合用户的数据分析需求。
    如果用户要求你进行数据分析，请尽量通过生成一个完整的可以直接运行的 Python 脚本进行数据分析，具体要求如下：
      1. 可以使用的库包括 micropip, numpy, scikit-learn, scipy, pandas以及Python的基本库（不用考虑安装问题，请直接使用）。
      2. 任务目标（在用户没有特别强调情况下）：
      - 根据提供的数据集，进行数据清洗、特征工程、模型训练等数据分析任务。具体任务可以根据数据集的特点自行决定。
      - 提供完整的数据分析过程，包括数据预处理、特征工程、模型训练、模型评估等步骤。
      - 提供清晰的数据分析结果，包括数据摘要、模型评估结果等。
      3. 输出格式要求所有的打印输出部分（如数据摘要、模型评估结果等）需合并成一个字符串作为结果返回，不用打印输出。

# token配置
token:
  # 令牌自定义标识
  header: ACCESS-TOKEN
  # 令牌密钥
  secret: NBgkqhkiG9w0BAQEFAASCBKgwggSkA
  # 令牌有效期（默认30分钟）
  expireTime: 30

# 用户配置
user:
  password:
    # 密码最大错误次数
    maxRetryCount: 5
    # 密码锁定时间（默认10分钟）
    lockTime: 10
